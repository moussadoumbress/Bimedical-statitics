---
title: 'TP `R` 1: Tests statistiques'
author: "Vos noms"
date: "Statistiques biomÃ©dicales"
output:
  html_document:
    toc: yes
    toc_depth: 2
  pdf_document:
    toc: yes
    toc_depth: '2'
subtitle: ''
header-includes: \usepackage[french]{babel}
---



# 1. Tests: quelques fonctions utiles 

## 1.1 Tests de normalité

 De nombreux tests ou IC sont valables sous l'hypothèse que l'échantillon est généré selon une loi normale. Il convient alors de tester la normalité de  l'échantillon. 

Il est possible d'installer la fonction `lillie.test` du package `nortest` à installer à l'aide de la commande `install.packages('nom_du_package')` ou manuellement dans l'onglet `Tools-> Install packages` de la barre de contrôle (ci-dessus). On peut aussi simplement utiliser la fonction `shapiro.test`.

**1.** Parmi les échantillons suivants, lesquels semblent de loi normale d'après les tests de Lilliefors et Shapiro-Wilks  ?

```{r,eval=FALSE}
###Exemple
library(nortest)
x1=c(12.672656, 13.762919,  7.386138,  9.936208, 11.758227, 13.718379, 12.543564, 14.635996, 15.682780, 10.175092)
x2=c(7, 8, 9, 10, 11, 12, 13, 14, 15, 16)
x3=c(2, 5, 4, 3, 4, 16, 15, 16, 15, 17)
x4=c(0,1,1,1,0,1,1,0,0,1) 
x5=rnorm(50,0,1)
x6=round(rnorm(50,0,1))
x7=round(rnorm(50,0,1),1)
x8=c(rnorm(50,20,1.5),rnorm(20,42,4))

x9=1:100

lillie.test(x1)
shapiro.test(x1)
```

## 1.2 Tests pour échantillon(s) de loi normale(s)  

Installer manuellement le package `OneTwoSamples` (le plus récent dans les [archive du CRAN](https://cran.r-project.org/src/contrib/Archive/OneTwoSamples/)); puis utiliser la librairie associée `library(OneTwoSamples).` Cela donne accès à `mean_test1` et `mean_test2` : des procédures de tests utilisant la loi normale avec variance connue ou inconnue. Voir aussi les fonctions `var_test1` et `var_test2`.


**2.** Commentez les résultats des trois lignes de codes suivantes en considérant un seuil de rejet à 5\%. Qu'est ce qui était prévisible(s) ?
```{r,eval=FALSE}
library(OneTwoSamples)
# Ligne 1:
mean_test1(rnorm(20,0,1),mu=1,side=-1,sigma=1)
# Ligne 2:
mean_test1(rnorm(20,0,1),mu=1,side=-1,sigma=4)
# Ligne 3:
mean_test1(rnorm(20,0,1),mu=1,side=1)
```
3. L'échantillon suivant correspond aux âges de 20 étudiants. Peut-on rejeter l'hypothèse $H_0$ que l'âge moyen des étudiants est inférieur ou égal à 20 ans (on vérifiera d'abord l'hypothèse de normalité) ? 
```{r}
AGE<-c(18,25,22,21,23,19,20,17,19,20,22,23,20,28,21,23,19,20,22,21)
```
**4.** Expliquer (ou prévoir) les résultats des lignes suivantes. On s'intéressera en particulier aux p-valeurs et aux dégrés de liberté. Que signifie `Z` et `T`?
```{r,eval=FALSE}
x=rnorm(10, mean = 10, sd = 1);
y=rnorm(20, mean = 10, sd = 1);
mean_test2(x, y, sigma = c(0.1, 0.1), side = 0)
mean_test2(x, y, var.equal = TRUE, side = 0)
```
**5.** Expliqer le résultat du code suivant et modifier les paramètres de la fonction pour qu'elle renvoie un résultat censé.
```{r,eval=FALSE}
x1=rnorm(20, mean=10, sd = 4)
x2=rnorm(10, mean=20, sd = 4)
var_test2(x1,x2,mu=c(10,10))
```


**6.** On dispose de deux échantillons de temps de révision pour le partiel de mathématiques, l'un en L1  biologie, l'autre en L1 psychologie. Les temps sont donnés en heures. On cherche à rejeter l'hypothèse $H_0$ que les étudiants de en psychologie révisent plus les maths que ceux de la filière biologie. Qu'en concluez-vous? On prendra toutes les garanties pour savoir si il est possible d'appliquer la fonction `mean_test2`. Expliquez le degré de liberté renvoyé par la fonction (aide de `R`, wikipédia ...)
```{r,eval=FALSE}
Temps_SD=c(2.1,0.9,2.6,2.9,3.9,1.3,0.2,3.6,1.0,1.4,2.3,4.1,1.2,4.1,3.6,2.6,2.4,1.4,3.1,2.8)
Temps_INFO=c(1.6, 0.8, 2.1, 1.4, 2.7, 1.1, 2.2, 1.1, 2.8, 0.9, 1.0, 1.3, 3.1, 1.8, 1.9, 1.8, 0.7, 2.5, 1.8, 1.4)
```
**7.** Une fonction alternative à `mean_test1` et `mean_test2` est `t.test`. Cependant cette fonction ne permet pas de traiter le cas de la variance connue. De même, `var.test` est une alternative à `var_test1` et `var_test2`, mais sans le cas de la moyenne connue. 
Peut-on rejeter au seuil de 5\% que les sardines de Bretagne  sont plus petites que celle de la mer méditérranée ? On utilisera les fonctions `t.test` et `var.test`.
```{r,eval=FALSE}
#taille en cm des sardines de Bretagne
x1=c(10.8,9.6,11.9,13.2,17.0,15.9,12.1,9.6,10.7,15.4)
#taille en cm des sardine de mer méditérranée
x2=c(10.4,8.9,8.5,13.1,9.0,8.6,8.7,7.9,11.3,10.6,8.6,11.9,11.2,10.6,8.3)
```

## 1.3 Tests asymptotiques basés sur le Théorème Central Limite

**8.** Bien que dédié aux échantillons de lois normales, il est possible d'utiliser les fonctions `mean_test1` et `mean_test2` pour effectuer des tests asymptotiques à l'aide du TCL. Expliquer comment faire. En particulier, on traitera le cas suivant. Peut-on rejeter l'hypothèse $H_0$ que le médicament 1 est plus efficace que le médicament 2 ?
```{r, eval=FALSE}
# On simule l'efficacité de deux médicaments
# 1, pour efficace, 0 sinon

# médicament 1
x1=rbinom(80,1, prob= 0.6)
#médicament 2
x2=rbinom(120,1, prob= 0.7)

```

## 1.4 Tests du $\chi^2$

La fonction chisq.test permet de réaliser les tests du $\chi^2$ de conformité, d'indépendance et d'homogénéité.

* Le test du $\chi^2$ de conformité permet de savoir si il y a correspondance entre une répartition théorique et une répartition observée. L'hypothèse $H_0$ est "la répartition est celle donnée par la théorie".

* Le test du $\chi^2$ d'indépendance permet d'étudier l'indépendance entre 2 critères susceptibles d'être associés à une différence de répartition. L'hypothèse $H_0$ est "la répartition ne dépend pas du critère".

* Le test du $\chi^2$ d'homogénéité permet d'étudier la correspondance entre les répartitions de différents échantillons. L'hypothèse $H_0$ est "les répartitions sont identiques".


**9.** Ici, la fonction à utiliser est `chisq.test` . Cette année, en M2, il y a 8 filles  et 15 garçons. Peut-on rejeter au seuil de 10\% qu'il y  autant de filles que  de garçons dans cette filière ? On effectuera un test de conformité standard. Est-il possible d'utiliser le tests du $\chi^2$ standard ou faut-il évaluer la p-valeur par simulation de Monte Carlo ?  



**11.** Exemple du test d'indépendance: compléter le code ci-dessous (matrice) pour savoir si il est possible de rejeter l'hypothèse d'indépendance entre le genre et la rémunération.
```{r,eval=FALSE}
# Dans une entreprise, les salaires on été étudiés en fonction du genre. Il se répartissent en trois classe: entre 1000 et 2000 euros, entre 2000 et 3000 euros, plus de 3000 euros.
# Créations des vecteurs correspondant aux 2 catégories :
hommes = c(110,80,50)
femmes = c(120,90,30)

# Création d'une matrice comparative. On veut que la ligne des valeurs pour les hommes correspondent à la ligne 1 de la matrice, et la ligne des valeurs pour les femmes correspondent à la ligne 2 de la matrice.

# Réalisation du test khi-deux - les résultats sont sauvegardés dans "khi_test"
khi_test = chisq.test(M)

khi_test # affiche le résultat du test
```

**12.** Les élèves de 3 classes de CP apprennent à lire selon trois méthodes différentes. La première valeur correspond au nombre de réussite à un test de lecture et la seconde au nombre d'échec. Compléter le code suivant à l'aide de `matrix` ou `rbind`. Les résultats des trois méthodes doivent constituer les trois lignes.
```{r,eval=FALSE}
meth1 = c(13,17)

meth2 = c(18, 9)

meth3 = c(20, 6)

# Réalisation du test khi-deux - les résultats sont sauvegardés dans "khi_test"
khi_test = chisq.test(M)
khi_test # affiche le résultat du test
```


## 1.5 ANOVA (Analysis of Variance)

*Un premier exemple*

L'analyse de la variance (ANOVA stands for **An**alysis **o**f **Va**riance)  a pour but  de tester l'égalité des moyennes entre plusieurs échantillons. C'est un test qui se base sur la normalité des échantillons et l'homogénéité des variances (homoscedasticité). Il faut donc contrôler que les échantillons peuvent être considérés comme issus de lois normales ('shapiro.test') et que leur variance semblent égales (`var.test`).

**13.** Le fichier `Anova.Rdata` contient  4 échantillons `x1`, ..., `x4`. Identifier un groupe d'échantillons vérifiant les hypothèses d'application de l'anova au seuil de 5%. Dans la suite, on travaille sur ces échantillons.
```{r,eval=FALSE}
load(file='Anova.Rdata')
```
**14.** Représenter les boxplots des échantillons sélectionnés (function `boxplot`).

__Rappel: ANOVA à un facteur__
Soit $x_1,\ldots, x_p$ des échantillons. L'échantillon $x_i$ comprend $n_i$ variables aléatoires de lois normales: $x_i=(x_{i,1},\ldots,x_{i,n_i}).$ 

On définit la somme des carrés entre groupe ($SSB$, between groups) et à l'intérieur des groupes ($SSW$, within groups ): $$SSB=\underset{i=1}{\overset{p} \sum} n_i (\overline{x_i}-\overline{x})^2,$$
et $$SSW=\underset{i=1}{\overset{p} \sum} \underset{j=1}{\overset{n_i} \sum} (x_{i,j}-\overline{x_i})^2,$$
avec $\overline{x}$ la moyenne de tous les échantillons réunis et $\overline{x_i}$ la moyenne de l'échantillon $x_i$. La statistique  $F$ suit une loi de Fisher:
$$F=\dfrac{\dfrac{SSB}{p-1}}{\dfrac{SSW}{n-p}}\sim \mathcal{F}(p-1,n-p)$$

**15.** Ecrire une fonction qui renvoit $SSB,$ $SSW$ , la statistique de tests et la $p$-valeur pour la loi de Fisher correspondant au test ANOVA à 1 facteur. Comparer les résultats obtenus avec ceux de la fonction 'oneway.test'.

```{r,eval=FALSE}
n1 <- n2 <- n3 <- 100
x1 <- rnorm(n1,2.65)
x2 <- rnorm(n2, 2.55)
x3 <- rnorm(n3, 3.2)
x <- c(x1,x2,x3)
m <- mean(x)

# mise en forme (regarder attentivement la forme que prennent ces données)
tab <- data.frame(value = x, group = c(rep(1,n1),rep(2,n2),rep(3,n3)))
# 
oneway.test(value~group, tab, var.equal = TRUE)
```

**16.** Appliquer l'ANOVA au jeu de données suivant: pour des décés de personnes retraités survenus entre 2010 et 2020, âge de décés et classe sociale. On réalisera les contrôles d'usages.

```{r,eval=FALSE}
data=read.csv("Life_expectancy.csv")
```


# 2. Exercices

__Exercice 1: Analyse de data frame__

**a. Naissance: **

C'est une base de donnée contenant la taille (en cm) et le sexe (1=masculin, 2=féminin) des nouveau-nés français en 2019. 

Naît-il plus de filles ou de garçons ? Y a-t-il une différence de taille à la naissance ? 
```{r}
data=read.csv("Naiss_fr_2019.csv")
```

**b. Espérance de vie:**

Le jeu de données suivant rassemble des informations sur des décès. On notera que la variable `SEXE` a été équilibrée ("autant" de femmes, que d'hommes dans chaque catégorie social). Il n'est donc pas possible d'étudier la répartition des hommes et des femmes dans ces catégories.

* `AGE`: âge de la personne décédée;
* `CLASSE`: la catégorie sociale du décédé;
* `SEXE`: 1, pour les hommes, 2, pour les femmes;
* `DATE`: date approximative du décès (3 classes).


```{r,eval=FALSE}
data=read.csv("Life_expectancy_large.csv")
```

__Exercice 2 : Tests exacts de Fisher.__

Le data frame suivant est composé des données d'un test clinique pour un traitement atténuant les ronflements. Celui-ci est testé contre un placebo.

* `T`: 1 pour le traitement, 0 pour le placebo;
* `X`:  moyenne du volume sonore (db) du ronflement sur la semaine précédent le test;
* `Y`: volume sonore (db) du ronflement durant la nuit du test.

```{r,eval=FALSE}
data=read.csv("Snoring_treatment.csv")
```

**1.** Effectuer un test exact de Fisher sur les 10 premiers patients (fonction `combn`).

**2.** Mettre en place un test exact de Fisher pour l'ensemble du data frame. Afin d'approximer la p-valeur par simulations de Monte Carlo, on pourra permuter l'ordre des patients en conservant l'ordre de traitement (fonction `sample.int`).

__Exercice 3 : Intervalles de confiance et tests pour les proportions.__ 

Soit $(X_1,\ldots,X_n)$ un $n$- échantillon de loi de bernoulli $\mathcal{B}(p).$ On rappelle que: $$\dfrac{\sqrt{n}  (\overline{X}_n-p)}{\sqrt{p(1-p)}}\overset{\mathcal{L}}{\underset{n\rightarrow +\infty}\longrightarrow} \mathcal{N}(0,1).$$
Le code suivant définis la fonction int.p permettant de calculer l'intervalle de confiance au niveau $\alpha$ (alpha) pour un $n$-échantillon de loi de Bernoulli.

```{r}
int.p = function(vector, conf.level, na.rm=T) {
     if (length(vector)==0) { cat("Erreur ! Le vecteur ",substitute(vector),"est vide.\n")} 
      else { 
      n = length(vector)-sum(is.na(vector)) 
      proba = (1-conf.level)*100 ; proba = (100-proba/2)/100 
      q_norm = qnorm(proba,0,1) # quantile 
      moyenne = mean(vector,na.rm=na.rm)  
      dist_max = q_norm * sqrt(moyenne*(1-moyenne)/n) 
      intervalle = c(moyenne-dist_max, moyenne+dist_max)
      return(list(intervalle=intervalle, moyenne=moyenne, dist_max)) }} 
```  

La ligne qui suit permet d'essayer la fonction int.p sur un $100$-échantillon de loi de Bernoulli $\mathcal{B}(0.2).$

```{r,eval=FALSE}
x = rbinom(100,1,0.2) ; int.p(x,conf.level = 0.9)
```
On charge les deux dataframes suivants:
```{r,eval=FALSE}

load(file="df_trait1.Rdata")
load(file="df_trait2.Rdata")
```
**0.** Appliquer la fonction int.p sur les données contenues dans ces dataframes.

Ces dataframes sont les réponses positives ou non de patient à un traitement. Le laboratoire pharmaceutique disposait du traitement 1 et à tenter de l'améliorer (traitement 2). Chacun des traitements 1 et 2 a été essayé sur deux groupes de 250 et 200 patients. Les résultats pour les traitements 1 et 2 sont rangés dans les dataframe df1 et df2. 

On rappelle que: $$\dfrac{D_n-(p_1-p_2)}{\sqrt{\dfrac{p_1(1-p_1)}{n_1}+ \dfrac{p_2(1-p_2)}{n_2}}}\overset{\mathcal{L}}{\underset{n\rightarrow +\infty}\longrightarrow} \mathcal{N}(0,1).$$

**1.** En vous inspirant de la fonction int.p, réaliser une fonction int.diff.p permettant de calculer l'intervalle de confiance au niveau $\alpha$ (alpha) pour la différence de deux $n$-échantillons de loi de Bernoulli. L'intervalle de confiance au niveau 95\% obtenu pour la différence $p_2-p_1$ est-il strictement positif?

**2.** Les investigateurs du projet trouvent que l'intervalle de confiance est trop grand. Ils hésitent à rajouter 150 patients pour le traitement 1 et 100 patients pour le traitement 2. En supposant que les estimations des variances pour chaque groupe sont correctes, quelle serait la nouvelle longueur de l'intervalle ? 

